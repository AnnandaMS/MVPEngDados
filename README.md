Objetivo: Construir um pipeline completo de dados utilizando serviços da AWS, para análise de informações sobre navios cargueiros ao redor do mundo.

Base de Dados: 
Dataset: Global Cargo Ships (Kaggle)

Serviços e Ferramentas Utilizadas:
Amazon S3 (armazenamento dos dados)
AWS Glue (ETL - extração, transformação e carga)
Amazon Redshift (armazenamento e consulta)
Ferramenta Change Schema (transformação)
SQL + Microsoft Excel (análise e visualizações)

Etapas do Projeto:
Upload dos dados para o Amazon S3
Criação de crawler e transformações com Glue e Change Schema
Carga dos dados em Redshift
Consulta via SQL
Geração de gráficos e insights com Excel

Resultado:
Pipeline funcional e escalável para análise de grandes volumes de dados logísticos.

Contexto: Projeto desenvolvido como parte da pós-graduação em Ciência de Dados e Análise.

